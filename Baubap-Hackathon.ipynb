{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37783c9-979c-4938-a98a-e6294381f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def load_data(csv_file_path):\n",
    "    return pd.read_csv(csv_file_path)\n",
    "\n",
    "def drop_zero_columns(df):\n",
    "    df_no_missing = df.dropna(axis = 1)\n",
    "    numeric_columns = df_no_missing.select_dtypes(include=np.number)\n",
    "    columns_with_all_zeros = (numeric_columns==0).all(axis = 0)\n",
    "    \n",
    "    return columns_with_all_zeros[columns_with_all_zeros].index, df.drop(columns = columns_with_all_zeros[columns_with_all_zeros].index)\n",
    "\n",
    "def remove_rows_with_missing_values_in_categorical(df):\n",
    "    categorical_columns = df.select_dtypes(include = ['object', 'category', 'bool']).columns\n",
    "    return df.dropna(subset = categorical_columns)\n",
    "\n",
    "def split_set_into_train_test(df, target_variable, test_size = 0.2):\n",
    "    X = df.drop(target_variable, axis = 1)\n",
    "    y = df[target_variable]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = 42, stratify = y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def imputation_of_missing_values(X_train, X_test, neighbors = 5):\n",
    "    numerical_variables = X_train.select_dtypes(include = np.number).columns\n",
    "    categorical_variables = X_train.select_dtypes(include = ['object', 'category', 'bool']).columns\n",
    "    \n",
    "    numerical_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown = 'ignore')\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', numerical_transformer, numerical_variables),\n",
    "        ('cat', categorical_transformer, categorical_variables)\n",
    "    ])\n",
    "\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "    knn_imputer = KNNImputer(n_neighbors = neighbors)\n",
    "    X_train  = knn_imputer.fit_transform(X_train_preprocessed)\n",
    "\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)\n",
    "    X_test = knn_imputer.transform(X_test_preprocessed)\n",
    "    \n",
    "    return X_train, X_test, preprocessor, knn_imputer\n",
    "\n",
    "def feature_selection(model, X_train, y_train, X_test, y_test, n_features_to_select=10):\n",
    "\n",
    "    model.set_params(scale_pos_weight= ((y_train.shape[0] - np.sum(y_train))/np.sum(y_train)))\n",
    "    \n",
    "    rfe = RFE(model, n_features_to_select=n_features_to_select)\n",
    "    X_train_selected = rfe.fit_transform(X_train, y_train)\n",
    "    X_test_selected = rfe.transform(X_test)\n",
    "\n",
    "    return rfe.support_, X_train_selected, X_test_selected\n",
    "\n",
    "def ensemble(model1, model2, model3, model4, voting = 'soft', weights = [2,2,1,1]):\n",
    "    ensemble_clf = VotingClassifier(estimators=[\n",
    "        (model1[0], model1[1]),\n",
    "        (model2[0], model2[1]),\n",
    "        (model3[0], model3[1]),\n",
    "        (model4[0], model4[1]),\n",
    "    ], voting='soft', weights = [2, 2, 1, 1])\n",
    "\n",
    "    return ensemble_clf\n",
    "\n",
    "def trained_model(X, y, model1, model2, model3, model4, voting = 'soft', weights = [2,2,1,1]):\n",
    "    ensemble_clf = ensemble(model1, model2, model3, model4, voting = 'soft', weights = [2,2,1,1])\n",
    "    ensemble_clf.fit(X, y)\n",
    "\n",
    "    return ensemble_clf\n",
    "\n",
    "def brier_score(X, y, ensemble):\n",
    "    y_pred_prob = ensemble.predict_proba(X)\n",
    "    return brier_score_loss(y, y_pred_prob[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a272c9b6-9e4d-47f5-8465-300876868120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09248407868959824\n"
     ]
    }
   ],
   "source": [
    "#Train and test model on dataset\n",
    "\n",
    "#load data_set\n",
    "df = load_data('/Users/danielmilanesperez/Documents/Projects/Baubap/training.csv')\n",
    "\n",
    "#preprocessing\n",
    "columns, df = drop_zero_columns(df)\n",
    "df = remove_rows_with_missing_values_in_categorical(df)\n",
    "X_train, X_test, y_train, y_test = split_set_into_train_test(df, 'Target')\n",
    "X_train, X_test, preprocesor, knn_imputer = imputation_of_missing_values(X_train, X_test, neighbors = 5)\n",
    "\n",
    "#feature_selection\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic', \n",
    "    eval_metric='logloss',          \n",
    "    scale_pos_weight = 1\n",
    ")\n",
    "\n",
    "support, X_train_selected, X_test_selected = feature_selection(model, X_train, y_train, X_test, y_test, n_features_to_select=25)\n",
    "\n",
    "#fitting ensemble\n",
    "logreg = ['logreg', LogisticRegression(C = 0.01, penalty = 'l2', random_state=42)]\n",
    "nn = ['nn', MLPClassifier(hidden_layer_sizes=(2, 1), max_iter=1000, alpha = 0.001, random_state=42)]\n",
    "xgb1 = ['xgb1', xgb.XGBClassifier(colsample_bytree =1.0, learning_rate= 0.1, max_depth= 3, n_estimators =50, subsample = 0.9, random_state=42)]\n",
    "knn = ['knn', KNeighborsClassifier(n_neighbors = 11, p = 2, weights ='distance')]\n",
    "\n",
    "#fiting ensemble\n",
    "ensemble_clf = trained_model(X_train_selected, y_train, logreg, nn, xgb1, knn, voting = 'soft', weights = [2,2,1,1])\n",
    "\n",
    "#testing dataset\n",
    "score = brier_score(X_test_selected, y_test, ensemble_clf)\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d25b31ea-252d-4ecd-9744-2af4912db139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0447652  0.04768859 0.05099318 0.12977546 0.10097523 0.03918252\n",
      " 0.10673232 0.25217856 0.13848109 0.09456977 0.13841767 0.15728146\n",
      " 0.06668847 0.07906028 0.12341708 0.04491834 0.12486109 0.07655304\n",
      " 0.08007658 0.10564003 0.13405514 0.139841   0.19393361 0.08571837\n",
      " 0.19400155 0.09373728 0.11977764 0.15766235 0.16346676 0.2111208\n",
      " 0.04616805 0.25064857 0.1882136  0.103408   0.17584503 0.07039037\n",
      " 0.13124767 0.24033026 0.18781955 0.25256605 0.20922111 0.15609227\n",
      " 0.09272003 0.09982888 0.13035699 0.08749442 0.10921712 0.16813727\n",
      " 0.14145855 0.23168571 0.16460631 0.15398552 0.13951911 0.076558\n",
      " 0.07016939 0.08650674 0.11910687 0.16536631 0.10378177 0.10617403\n",
      " 0.40628396 0.08801493 0.10094703 0.19316488 0.14757991 0.12855651\n",
      " 0.0830367  0.08115062 0.09537716 0.06052994 0.09124032 0.11408032\n",
      " 0.10126475 0.28150649 0.05715936 0.08246008 0.21086741 0.11561818\n",
      " 0.0885278  0.09043764 0.28241146 0.20690271 0.24448686 0.09003643\n",
      " 0.12885218 0.19256578 0.06128373 0.09446117 0.40815211 0.33009747\n",
      " 0.12471943 0.12285238 0.08186236 0.23619371 0.13674827 0.0736543\n",
      " 0.08560373 0.19956058 0.07917757 0.20196245 0.14555773 0.1112752\n",
      " 0.31819786 0.10469929 0.23202126 0.12228036 0.05939028 0.19757768\n",
      " 0.15237721 0.13168536 0.32462044 0.0836549  0.0735224  0.04080066\n",
      " 0.21549228 0.12987707 0.12062051 0.56360138 0.22687253 0.08240395\n",
      " 0.28411587 0.13865589 0.06011361 0.15022652 0.11293003 0.13683999\n",
      " 0.17175834 0.07569154 0.06246702 0.08469781 0.11949167 0.10821642\n",
      " 0.0661724  0.11231185 0.21776267 0.10801777 0.10055062 0.0973485\n",
      " 0.09094    0.2619866  0.13316997 0.18833467 0.21403267 0.17074627\n",
      " 0.06047363 0.14287315 0.11369284 0.14808518 0.12540074 0.12408048\n",
      " 0.155147   0.27993814 0.06615374 0.07467344 0.11810393 0.04565748\n",
      " 0.05261357 0.05906033 0.13551218 0.09600575 0.33702701 0.32848672\n",
      " 0.19801971 0.10839927 0.12778291 0.05230393 0.04979216 0.06132226\n",
      " 0.13091222 0.13132688 0.1620436  0.07582921 0.22821467 0.11680391\n",
      " 0.1012739  0.0795517  0.10076582 0.19900837 0.04929578 0.05411051\n",
      " 0.06775685 0.16306821 0.11485685 0.17441654 0.10317731 0.52845563\n",
      " 0.18887715 0.10088304 0.21242712 0.10470673 0.07378789 0.10025251\n",
      " 0.20337215 0.13702988 0.2075964  0.13824824 0.15348641 0.08492237\n",
      " 0.10381571 0.04699389 0.152064   0.05388754 0.1469157  0.21242919\n",
      " 0.04182577 0.06631267 0.08247028 0.13453183 0.06331057 0.07088184\n",
      " 0.07437881 0.10038008 0.058293   0.10697902 0.1147782  0.0456605\n",
      " 0.06074405 0.10258113 0.08224054 0.12198474 0.03621158 0.05738307\n",
      " 0.0414596  0.16001434 0.17977528 0.04744    0.12156255 0.08008587\n",
      " 0.16870864 0.11235668 0.13646926 0.03994615 0.19266389 0.10160698\n",
      " 0.06395311 0.11990066 0.05346631 0.11831123 0.1861196  0.09782252\n",
      " 0.04604492 0.14183903 0.12049471 0.2340054  0.14268552 0.15395436\n",
      " 0.0685471  0.08258574 0.21628924 0.33186625 0.09041538 0.09051358\n",
      " 0.07979175 0.07397759 0.06049685 0.13957373 0.09610907 0.30220876\n",
      " 0.05214922 0.32199772 0.06202603 0.1137109  0.07844884 0.04639266\n",
      " 0.06102145 0.18859138 0.07604005 0.09733572 0.1174731  0.08558369\n",
      " 0.1689392  0.34987847 0.08401356 0.11144788 0.21815301 0.15715173\n",
      " 0.22021644 0.17983968 0.13249888 0.14015784 0.1748703  0.04469265\n",
      " 0.08316759 0.11053262 0.2118831  0.08806242 0.5592967  0.09018739\n",
      " 0.07243521 0.12938493 0.14184336 0.07971233 0.14942077 0.08377012\n",
      " 0.55095863 0.11538481 0.09986479 0.16162151 0.07156351 0.07578549\n",
      " 0.09773174 0.117821   0.11318285 0.12617056 0.46488079 0.10330982\n",
      " 0.20836513 0.08999696 0.07376993 0.12539362 0.08023429 0.41923936\n",
      " 0.10403566 0.15070596 0.25399147 0.17789721 0.49774826 0.12088195\n",
      " 0.07934555 0.14783285 0.24643094 0.09396757 0.06575769 0.05172147\n",
      " 0.31165543 0.1432502  0.13545285 0.06551015 0.17860891 0.32133443\n",
      " 0.04178031 0.12536579 0.09876432 0.10236996 0.12054445 0.21706154\n",
      " 0.11639499 0.06317355 0.20113698 0.06690109 0.13275869 0.08662895\n",
      " 0.05175541 0.13030428 0.17857832 0.05844695 0.18111152 0.0863444\n",
      " 0.17064453 0.11628668 0.08525342 0.17302075 0.08127153 0.0865543\n",
      " 0.09983751 0.0581979  0.06664206 0.09799159 0.10065557 0.09176522\n",
      " 0.07287417 0.16686186 0.10950396 0.14658523 0.12364239 0.09774295\n",
      " 0.14318205 0.08606084 0.25870909 0.199371   0.36742192 0.07709004\n",
      " 0.14886202 0.0882505  0.07864984 0.09693629 0.20170567 0.1000452\n",
      " 0.37536494 0.14737038 0.23289803 0.21250258 0.08641708 0.12105393\n",
      " 0.12764457 0.10301891 0.12819927 0.11321958 0.05912149 0.07489677\n",
      " 0.08128046 0.09071071 0.11768004 0.14577465 0.20075552 0.09607004\n",
      " 0.29001291 0.13027729 0.04412159 0.07173637 0.22072625 0.07654464\n",
      " 0.06448736 0.05473712 0.44145121 0.1244908  0.05414426 0.08034946\n",
      " 0.23796537 0.13606635 0.09614101 0.08726497 0.1056103  0.070975\n",
      " 0.12486423 0.16022142 0.08322379 0.09145625 0.09365453 0.04040878\n",
      " 0.12035443 0.07788094 0.09214595 0.08359841 0.14640578 0.06008029\n",
      " 0.08174296 0.0959945  0.21995516 0.11741841 0.06121296 0.22115552\n",
      " 0.06272428 0.09032061 0.12622253 0.14640489 0.11670242 0.10574294\n",
      " 0.09502743 0.12789516 0.12517137 0.05242251 0.10724826 0.0405013\n",
      " 0.08608222 0.09536829 0.09188735 0.14528665 0.11500334 0.26555692\n",
      " 0.13553892 0.13397569 0.1535388  0.0882554  0.10418484 0.25080982\n",
      " 0.06378304 0.21552142 0.14735326 0.13677048 0.07563152 0.09501437\n",
      " 0.08597492 0.13432238 0.10681513 0.1365349  0.11861233 0.11585044\n",
      " 0.20930916 0.13837803 0.12696006 0.07114799 0.19933046 0.07839013\n",
      " 0.14902453 0.05677554 0.14488066 0.06097175 0.10019    0.26226911\n",
      " 0.2578625  0.16936893 0.11319059 0.15158429 0.17789737 0.09910518\n",
      " 0.24016685 0.28878203 0.10753944 0.11216977 0.05644811 0.14898551\n",
      " 0.08489744 0.19773531 0.08821831 0.09418014 0.06802271 0.12373187\n",
      " 0.21241301 0.07646182 0.09462804 0.18956707 0.09972127 0.18825361\n",
      " 0.6471627  0.08460837 0.45322244 0.06336806 0.08326808 0.09815934\n",
      " 0.07089547 0.09304332 0.19219015 0.11906206 0.12860193 0.07285013\n",
      " 0.15116566 0.1270713  0.0651486  0.13014338 0.2085984  0.22966939\n",
      " 0.11308763 0.26198141 0.32059606 0.20810051 0.07307796]\n"
     ]
    }
   ],
   "source": [
    "#load data_set\n",
    "validation = load_data('/Users/danielmilanesperez/Downloads/data_evaluation.csv')\n",
    "\n",
    "#preprocessing\n",
    "validation.drop(columns = columns)\n",
    "X_preprocesed = preprocesor.transform(validation)\n",
    "X = knn_imputer.transform(X_preprocesed)\n",
    "X_final = X[:, support]\n",
    "\n",
    "X_pred = ensemble_clf.predict_proba(X_final)\n",
    "print(X_pred[:, 1])\n",
    "\n",
    "np.savetxt('/Users/danielmilanesperez/Downloads/data_evaluation_how-u-doing.csv', X_pred[:,1], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b27616-d161-471c-b015-f0a5fa2b2fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
